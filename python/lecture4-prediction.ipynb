{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Process Mining Module\n",
    "\n",
    "This notebook is part of an Applied Process Mining module. The collection of notebooks is a *living document* and subject to change. \n",
    "\n",
    "# Lecture 4 - 'Predictive Process Mining' (Python / PM4Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "<img src=\"https://pm4py.fit.fraunhofer.de/static/assets/images/pm4py-site-logo-padded.png\" alt=\"PM4Py\" style=\"width: 200px;\"/>\n",
    "\n",
    "In this notebook, we are using the [PM4Py library](https://pm4py.fit.fraunhofer.de/) in combination with several standard Python data science libraries:\n",
    "\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [PyTorch](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform the commented out commands to install the dependencies\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install pm4py\n",
    "# %pip install torch\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Process Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Log \n",
    "\n",
    "We are using the Sepsis event log as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis = pd.read_csv(\"../data/sepsis.csv\", sep=';')\n",
    "sepsis_log = pm4py.format_dataframe(sepsis, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\n",
    "sepsis_log = pm4py.convert_to_event_log(sepsis_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd982e1f-dbf3-4a6c-bce1-c8a295e56ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sepsis_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d64ea8-e901-46ca-9a46-6c7abf3fa68a",
   "metadata": {},
   "source": [
    "## Feature Extraction / Encoding\n",
    "\n",
    "We are using the PM4Py functionality to do [feature selection and processing](https://pm4py.fit.fraunhofer.de/documentation/1.5#item-7-0-1) of the event log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a9625-4aca-4429-b467-2c118a2ea431",
   "metadata": {},
   "source": [
    "### Set of Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b66ef-0ddf-40a5-adb4-361b5a77eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
    "from pm4py.objects.log.util.log import project_traces\n",
    "\n",
    "data, feature_names = log_to_features.apply(sepsis_log, parameters={\"str_ev_attr\": [\"concept:name\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard encoding of the `concept:name` attribute (i.e., the event label) is a one-hot encoded vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1st trace : \" + str(project_traces(sepsis_log)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e71c6d-580f-4aae-a68e-e5143fb1a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1st trace encoded: \" + str(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the number corresponds to the index in the following feature label vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5ca9a-8ea0-47cd-ae4d-bf54a1a03e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try again for a different trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2nd trace : \" + str(project_traces(sepsis_log)[1]))\n",
    "print(\"2nd trace encoded: \" + str(data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall data shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a2e83-3a45-409d-82b4-2d0101273fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982a66c-24c6-4f3f-b2cb-a42abab23b69",
   "metadata": {},
   "source": [
    "So, PM4Py gives us a *one-hot encoding* of the so called *set abstraction* of the event log. This means there are 16 distinct activities in the event log and the feature vector simply encodes whether that activity is present or not in the data. \n",
    "\n",
    "Let us have a look at the distribution of these feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514b73c-ba13-47f1-bce9-fc64684783ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_features = np.unique(data, return_counts= True, axis = 0)\n",
    "dist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d3f26-b06b-4aae-8f55-7e3e0c5e4acd",
   "metadata": {},
   "source": [
    "What is the most common feature vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315b957-063d-476c-ad7a-7bd1682b350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_features[0][np.argmax(dist_features[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6b973-dcbb-4719-8758-2ca4e64be582",
   "metadata": {},
   "source": [
    "Makes sense, almost all activities actually are bound to occur in this process. There are only few choices.\n",
    "So, this encoding is likely not the most useful one but a very simple one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2gram, feature_names = log_to_features.apply(sepsis_log, parameters={\"str_evsucc_attr\": [\"concept:name\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1st trace : \" + str(project_traces(sepsis_log)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1st trace encoded: \" + str(data_2gram[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f5556-a1a5-48b1-9f3b-574f5ccb172c",
   "metadata": {},
   "source": [
    "### Bag of Words / Multiset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option would be to use the encoding known as `bag of words` in Natural Language Processing, which is constructing a multiset of the one-hot encoded events. So, the frequency with which each activity occurs is reflected.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sepsis.loc[:,[\"case_id\"]].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have a NA value in the case attribute let us fix this by replacing with a String (in real world data you should be looking for the underlying reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis = sepsis.fillna(\"MISSING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sepsis.loc[:,[\"case_id\"]].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better. Now lets build a bag of words representation by grouping our data and then counting the number of events refering to the individual activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_multiset_pd = sepsis.loc[:,[\"case_id\", \"activity\"]].groupby([\"case_id\", \"activity\"]).size().unstack(fill_value=0)\n",
    "sepsis_multiset_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiset = np.asarray(sepsis_multiset_pd)\n",
    "data_multiset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1st trace : \" + str(project_traces(sepsis_log)[0]))\n",
    "print(\"1st trace encoded: \" + str(data_multiset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2nd trace : \" + str(project_traces(sepsis_log)[1]))\n",
    "print(\"2nd trace encoded: \" + str(data_multiset[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already gives us more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078eaf4-0033-4190-8540-e9d903e6873f",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Let us try to build a basic prediction model based on this information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a61ac6-d144-4c72-a184-2af014e07616",
   "metadata": {},
   "source": [
    "### Throughput time\n",
    "\n",
    "We aim to predict the throughput time of a case. So let us look at the distribution of throughput time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d03b2-106c-4b61-b2fd-c1d63fbfe69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.statistics.traces.generic.log import case_statistics\n",
    "\n",
    "durations = np.asarray(case_statistics.get_all_case_durations(sepsis_log, parameters={ case_statistics.Parameters.TIMESTAMP_KEY: \"time:timestamp\"} ))\n",
    "durations = np.expand_dims(durations, 1)\n",
    "len(durations)\n",
    "durations = durations / 60 / 60 / 24 # in days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049de87d-0c94-4a9b-8eea-8b494cd2bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(durations).boxplot().set_ylabel('Throughput time (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = durations.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_duration = 0.5\n",
    "max_duration = 100\n",
    "\n",
    "data = np.asarray(data)[np.where((durations < max_duration) & (durations > min_duration))]\n",
    "data_2gram = np.asarray(data_2gram)[np.where((durations < max_duration) & (durations > min_duration))]\n",
    "data_multiset = data_multiset[np.where((durations < max_duration) & (durations > min_duration))]\n",
    "durations = durations[np.where((durations < max_duration) & (durations > min_duration))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(durations).boxplot().set_ylabel('Throughput time (days)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "data_scaled = scaler_x.fit_transform(data_input)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "durations_scaled = scaler_y.fit_transform(durations.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of PyTorch to build a simple Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bc0a1-e4c7-45f4-a43a-d5995ee9a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# We need float32 data\n",
    "x = torch.from_numpy(data_scaled.astype('float32'))\n",
    "y = torch.from_numpy(durations_scaled.astype('float32'))\n",
    "\n",
    "# Always check the shapes\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "ds = TensorDataset(x, y)\n",
    "train_dataloader = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check a random single sample from our data loader (always a good idea!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_dataloader))\n",
    "print(inputs[0])\n",
    "print(classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c0a7a-f710-40cb-bfa6-f7181bdd6411",
   "metadata": {},
   "source": [
    "Let's define a simple network and try to overfit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e9a89-0c57-4cb2-9e4f-62f2ec90c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(            \n",
    "            torch.nn.Linear(x.shape[1], 8),\n",
    "            nn.BatchNorm1d(num_features=8),\n",
    "            nn.LeakyReLU(),            \n",
    "            torch.nn.Linear(8, 32),\n",
    "            nn.BatchNorm1d(num_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(num_features=32),\n",
    "            nn.LeakyReLU(),            \n",
    "            torch.nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c5c80-f753-41dc-880f-cf473846ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb53eb-e636-4f11-ab8e-f04c3c36a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, measure_fn, optimizer, epochs, print_interval = 10):\n",
    "    \n",
    "    losses = []\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for epoch in range(epochs):    \n",
    "        \n",
    "        loop = tqdm(dataloader)\n",
    "\n",
    "        for batch, (X, y) in enumerate(loop):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(pred, y)\n",
    "            measure = measure_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append([loss.item(), measure.item()])\n",
    "\n",
    "            loop.set_description('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "            loop.set_postfix(loss=loss.item(), measure=measure.item())\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542533dd-79f4-41c8-979e-edc9d0889309",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "measure_fn = nn.L1Loss() # MAE\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "results = train(train_dataloader, model, loss_fn, measure_fn, optimizer, 200)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb3f43-4d8f-4024-8698-4c537739acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = pd.DataFrame(results).rolling(window=32).mean()\n",
    "results_data.columns = ['loss', 'measure']\n",
    "ax = results_data.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452365b1-e9a3-41bf-bad2-515545cb9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \" + str(scaler_y.inverse_transform(np.asarray(results[len(results)-1][1]).reshape(-1, 1))))\n",
    "\n",
    "data_mean = durations.mean()\n",
    "print(\"Data mean: \" + str(data_mean))\n",
    "print(\"Data MAE for prediction simply the mean: \" + str((np.absolute(durations - data_mean).mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extend this example with other encodings and a proper (!) evaluation for sequential event log data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
